{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Scope:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of your clients is a large real estate investment company. They invest in houses, appartments and condos within a small county in New York state. As a part of their business, they want to try and predict the fair transaction price of a property before it's sold.\n",
    "\n",
    "**Current solution:** The company currently uses a third party appraisal service. Appraisers are professionals who visit a property and estimate a fair price using their expertise or their own sets of metrics and checklists. Unfortunately, the skill levels of appraisers can vary greatly. The company compared the appraiser prices to actual transaction prices and they found that the estimates given by the inexperienced appraisers were **off by $70,000** on average.\n",
    "\n",
    "**Your role:** The company has hired you to find a data driven approach to value properties. They currently have a dataset for transaction prices for previously sold properties on the market and your goal is to build a real estate pricing model using that dataset.\n",
    "\n",
    "**Goal:** Build a model to predict transaction prices with an average error of under $70,000.\n",
    "\n",
    "**Specifics:** \n",
    "\n",
    "* Machine Learning task: Regression model \n",
    "* Target variable: Transaction price \n",
    "* Input variables: Refer to data dictionary file - \"Real Estate Project - Data Dictionary\" \n",
    "* Success Criteria: Mean Absolute Error (MAE) < $70,000\n",
    "\n",
    "This project will be carried out in 4 stages\n",
    "\n",
    "1. **Exploratory Data Analysis: Data understanding and generating insights**\n",
    "2. Data Cleaning & Data Preparation: Preparing data for Modelling\n",
    "3. Data Modelling: Experimenting with different algorithms\n",
    "4. Model Evaluation: Evaluate using performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal with this lecture is to **\"get to know\"** the data. Try to learn as much about the data as possible, but don't spend too much time and get stuck on this step. You will probably need to do ad-hoc data exploration later. Remember, the **CRISP-DM** process is iterative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas for Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display plots in the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# Seaborn for easier visualization\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `%matplotlib inline` helps plot the chart without having to use `plt.show( )` everytime. This is useful in Jupyter, but in IDE' like Spyder, we have to do `plt.show( )` to see the chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load 'real_estate.csv' in a pandas dataframe 'df'\n",
    "df = pd.read_csv('real_estate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to understanding your dataset is to display its basic information. This will give you a high-level understanding of your dataset's structure, features, and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the dataset using .head()\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of displaying examples from the dataset is not to perform rigorous analysis. Instead, try to get a qualitative \"feel\" for the dataset.\n",
    "\n",
    "Answer these questions below:\n",
    "\n",
    "* Do the columns make sense?\n",
    "* Do the values in those columns make sense?\n",
    "* Is missing data going to be a big problem based on an eyeball test?\n",
    "* What types of classes are there?\n",
    "\n",
    "Spend a couple minutes looking over the data to get familiar with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it's also helpful to look at the last 5 rows of data.\n",
    "* Sometimes datasets will have **corrupted data** hiding at the very end (depending on the data source).\n",
    "* It never hurts to double-check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last 5 rows of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the shape, or the dimensions of the dataset using the '.shape' attribute\n",
    "# Dataframe dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have **1883 observations and 11 features**. One of those features is technically the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, let's take a look at the data types of our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column datatypes using .dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all of the columns are numeric, except for 1 categorical column:\n",
    "\n",
    "* `'property_type'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check to see if any data types are incorrect.\n",
    "\n",
    "* Check if any numeric features should be categorical instead based on what you know about the dataset.\n",
    "* Or, check if any categorical features should be numeric instead.\n",
    "* It's fine if you are unsure about some columns, as we'll continue to explore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most enlightening data exploration tasks is plotting the distributions of your features.\n",
    "\n",
    "**Here are a few things to look out for:**\n",
    "* Distributions that don't make sense (e.g a large spike in houses with 10 bedrooms)\n",
    "* Potential outliers that don't make sense\n",
    "* Sparse data\n",
    "* Numeric features that should be categorical\n",
    "* Features that should be binary\n",
    "* Boundaries that don't make sense (e.g. percent values above 100 or below 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to display distributions of numeric features is by using seaborn' Pairplot.\n",
    "* Seaborn comes with a `.pairplot()` function that plots the distributions of all of the numeric features.\n",
    "* Also call `plt.show()` to clear all of the text \"residue\" and just keep the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram grid using seaborn pairplot\n",
    "\n",
    "# Clear the text \"residue\" and show the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the formal summary statistics.\n",
    "* Pandas comes with a `.describe()` function for summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display summary statistics for the numerical features again. Then, answer the following questions:\n",
    "1. In our dataset, what is the earliest transaction year (**year_sold**)?\n",
    "2. Among all properties in our dataset, what is the maximum number of bedrooms (**beds**)?\n",
    "3. In our dataset, do we see more variance in the number of bedrooms (**beds**) or the number of bathrooms (**baths**)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize numerical features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also find other useful information such as mean, std (standard deviation), and the 25%, 50%, 75% quartiles.**\n",
    "\n",
    "* For example, it looks like the `'basement'` feature only has the value `1`\n",
    "* We know this because its standard deviation is `0`, while its min and max are both `1`\n",
    "* `'basement'` also has missing values! You can tell because its count is only 1657 (out of a total of 1883 observations). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">Note: We have to change the basement variable to a boolean type and handle the missing values.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Segmentations</span>\n",
    "\n",
    "Segmentations are powerful ways to cut the data to observe the relationship between **categorical features and numeric features**.\n",
    "\n",
    "#### Segment <code style=\"color:steelblue\">'sqft'</code> by <code style=\"color:steelblue\">'property_type'</code> and plot the boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a box plot of sqft by property_type using seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After producing the plot, answer these questions:\n",
    "* Which type of property is larger, on average?\n",
    "* Which type of property sees greater variance in sizes?\n",
    "* Does the difference in distributions between classes make intuitive sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a box plot of price by property_type using seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After producing the plot, answer these questions:\n",
    "* Which type of property is more expensive?\n",
    "* What do those outliers signify in the `Bunglow` class?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">Note: Take care of these outliers </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations</span>\n",
    "\n",
    "Finally, let's take a look at the relationships between numeric features and other numeric features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation is a value between -1 and 1 that represents how closely values for two separate features move in unison.**\n",
    "* Positive correlation means that as one feature increases, the other increases.\n",
    "    <br>E.g. a child's age and their height.\n",
    "* Negative correlation means that as one feature increases, the other decreases.\n",
    "    <br>E.g. hours spent studying and number of parties attended.\n",
    "* Correlations near -1 or 1 indicate a strong relationship.\n",
    "* Those closer to 0 indicate a weak relationship.\n",
    "* 0 indicates no relationship.\n",
    "\n",
    "Pandas DataFrames come with a useful function for calculating correlations: `.corr()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations between numeric features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable now has a big dataframe that contains all of the correlations between numeric features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's too much information! After all, it's just a big rectangular dataset. So let's visualize this.\n",
    "\n",
    "But first, it's important to notice that the correlations for `'basement'` all show as `NaN`. This is expected because right now that feature doesn't vary at all (its standard deviation is 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try to visualize the correlation grid and make it easier.**\n",
    "* Seaborn's helpful `sns.heatmap()` function comes handy.\n",
    "* The `cmap= argument` controls the color palette used in the heatmap. We will set it to the value of `RdBu_r`. So positive correlation values will be red and negative correlation values will be blue.\n",
    "* By the way, what do you think will happen if you put in  `cmap=RdBu` instead of `RdBu_r`? Go ahead and try this out in your Workbook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations between numeric features\n",
    "# Plot heatmap of correlations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, when plotting a heatmap of correlations, it's often helpful to do 2 things:\n",
    "1. Annotate the cell with their correlations values\n",
    "2. Change the size of the figure\n",
    "\n",
    "#### 1. First, change the background to white.\n",
    "* Make the figure size 10 x 8  using <code style=\"color:steelblue\">plt.figure(figsize=(10,8))</code> so that the plot is a bit larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Next, display the correlation values in each cell.\n",
    "* The <code style=\"color:steelblue\">annot=</code> argument controls whether to annotate each cell with its value. By default, it's <code style=\"color:crimson\">False</code>.\n",
    "* To make the chart cleaner, multiply the <code style=\"color:steelblue\">correlations</code> DataFrame by 100 before passing it to the heatmap function.\n",
    "* Pass in the argument <code style=\"color:steelblue\">fmt=<span style=\"color:crimson\">'.0f'</span></code> to format the annotations to a whole number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the figsize 10 x 8\n",
    "\n",
    "# Plot heatmap of annotated correlations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most helpful way to interpret this correlation heatmap is to start by scanning the left side and find the row with our target variable, which is `'price'`.\n",
    "\n",
    "* Then, scan across to see if any of the boxes are dark red (strong positive correlation) or dark blue (strong negative correlation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before jumping to the next module, I would recommend going back and reviewing the charts you made. This time, since you've already created them, you can move through more quickly and really start to understand the **story** behind the data."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
